{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8f679cf",
   "metadata": {},
   "source": [
    "## <div align=\"center\"> TUGAS LAB IS794 DEEP LEARNING </div>\n",
    "### <div align=\"center\"> WEEK [05] : [Classification] </div>\n",
    "\n",
    "#### <div align=\"center\"> Semester Ganjil 2023/2024 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bf73dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24f12960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2017</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2013</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2014</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2016</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2017</td>\n",
       "      <td>Pune</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2013</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4649</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2013</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4650</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2018</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2012</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2015</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4653 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Education  JoiningYear       City  PaymentTier  Age  Gender EverBenched   \n",
       "0     Bachelors         2017  Bangalore            3   34    Male          No  \\\n",
       "1     Bachelors         2013       Pune            1   28  Female          No   \n",
       "2     Bachelors         2014  New Delhi            3   38  Female          No   \n",
       "3       Masters         2016  Bangalore            3   27    Male          No   \n",
       "4       Masters         2017       Pune            3   24    Male         Yes   \n",
       "...         ...          ...        ...          ...  ...     ...         ...   \n",
       "4648  Bachelors         2013  Bangalore            3   26  Female          No   \n",
       "4649    Masters         2013       Pune            2   37    Male          No   \n",
       "4650    Masters         2018  New Delhi            3   27    Male          No   \n",
       "4651  Bachelors         2012  Bangalore            3   30    Male         Yes   \n",
       "4652  Bachelors         2015  Bangalore            3   33    Male         Yes   \n",
       "\n",
       "      ExperienceInCurrentDomain  LeaveOrNot  \n",
       "0                             0           0  \n",
       "1                             3           1  \n",
       "2                             2           0  \n",
       "3                             5           1  \n",
       "4                             2           1  \n",
       "...                         ...         ...  \n",
       "4648                          4           0  \n",
       "4649                          2           1  \n",
       "4650                          5           1  \n",
       "4651                          2           0  \n",
       "4652                          4           0  \n",
       "\n",
       "[4653 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.read_csv(\"Employee.csv\")\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63140f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "cat_cols = ['Education', 'City', 'Gender']\n",
    "\n",
    "# Encode Categorical Data\n",
    "df_encoded = pd.DataFrame(encoder.fit_transform(training_df[cat_cols]))\n",
    "df_encoded.columns = encoder.get_feature_names_out(cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed47696c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education_Bachelors</th>\n",
       "      <th>Education_Masters</th>\n",
       "      <th>Education_PHD</th>\n",
       "      <th>City_Bangalore</th>\n",
       "      <th>City_New Delhi</th>\n",
       "      <th>City_Pune</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4649</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4650</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4653 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Education_Bachelors  Education_Masters  Education_PHD  City_Bangalore   \n",
       "0                     1.0                0.0            0.0             1.0  \\\n",
       "1                     1.0                0.0            0.0             0.0   \n",
       "2                     1.0                0.0            0.0             0.0   \n",
       "3                     0.0                1.0            0.0             1.0   \n",
       "4                     0.0                1.0            0.0             0.0   \n",
       "...                   ...                ...            ...             ...   \n",
       "4648                  1.0                0.0            0.0             1.0   \n",
       "4649                  0.0                1.0            0.0             0.0   \n",
       "4650                  0.0                1.0            0.0             0.0   \n",
       "4651                  1.0                0.0            0.0             1.0   \n",
       "4652                  1.0                0.0            0.0             1.0   \n",
       "\n",
       "      City_New Delhi  City_Pune  Gender_Female  Gender_Male  JoiningYear   \n",
       "0                0.0        0.0            0.0          1.0         2017  \\\n",
       "1                0.0        1.0            1.0          0.0         2013   \n",
       "2                1.0        0.0            1.0          0.0         2014   \n",
       "3                0.0        0.0            0.0          1.0         2016   \n",
       "4                0.0        1.0            0.0          1.0         2017   \n",
       "...              ...        ...            ...          ...          ...   \n",
       "4648             0.0        0.0            1.0          0.0         2013   \n",
       "4649             0.0        1.0            0.0          1.0         2013   \n",
       "4650             1.0        0.0            0.0          1.0         2018   \n",
       "4651             0.0        0.0            0.0          1.0         2012   \n",
       "4652             0.0        0.0            0.0          1.0         2015   \n",
       "\n",
       "      PaymentTier  Age  EverBenched  ExperienceInCurrentDomain  LeaveOrNot  \n",
       "0               3   34            0                          0           0  \n",
       "1               1   28            0                          3           1  \n",
       "2               3   38            0                          2           0  \n",
       "3               3   27            0                          5           1  \n",
       "4               3   24            1                          2           1  \n",
       "...           ...  ...          ...                        ...         ...  \n",
       "4648            3   26            0                          4           0  \n",
       "4649            2   37            0                          2           1  \n",
       "4650            3   27            0                          5           1  \n",
       "4651            3   30            1                          2           0  \n",
       "4652            3   33            1                          4           0  \n",
       "\n",
       "[4653 rows x 14 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace Categotical Data with Encoded Data\n",
    "training_df = training_df.drop(cat_cols ,axis=1)\n",
    "training_df = pd.concat([df_encoded, training_df], axis=1)\n",
    "\n",
    "# Encode target value\n",
    "training_df['EverBenched'] = training_df['EverBenched'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fe7ff3",
   "metadata": {},
   "source": [
    "## Question 1: Explain the function of this encoder\n",
    "\n",
    "Encoder di atas digunakan untuk menngubah kolom kategorikal Education, City, Gender, dan EverBenched menjadi biner 1/0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dc1e263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education_Bachelors</th>\n",
       "      <th>Education_Masters</th>\n",
       "      <th>Education_PHD</th>\n",
       "      <th>City_Bangalore</th>\n",
       "      <th>City_New Delhi</th>\n",
       "      <th>City_Pune</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.039638</td>\n",
       "      <td>3</td>\n",
       "      <td>0.954645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.107233</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.288732</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.570515</td>\n",
       "      <td>3</td>\n",
       "      <td>1.783563</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.502921</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.495961</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.039638</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.117650</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education_Bachelors  Education_Masters  Education_PHD  City_Bangalore   \n",
       "0                  1.0                0.0            0.0             1.0  \\\n",
       "1                  1.0                0.0            0.0             0.0   \n",
       "2                  1.0                0.0            0.0             0.0   \n",
       "3                  0.0                1.0            0.0             1.0   \n",
       "4                  0.0                1.0            0.0             0.0   \n",
       "\n",
       "   City_New Delhi  City_Pune  Gender_Female  Gender_Male  JoiningYear   \n",
       "0             0.0        0.0            0.0          1.0     1.039638  \\\n",
       "1             0.0        1.0            1.0          0.0    -1.107233   \n",
       "2             1.0        0.0            1.0          0.0    -0.570515   \n",
       "3             0.0        0.0            0.0          1.0     0.502921   \n",
       "4             0.0        1.0            0.0          1.0     1.039638   \n",
       "\n",
       "   PaymentTier       Age  EverBenched  ExperienceInCurrentDomain  LeaveOrNot  \n",
       "0            3  0.954645            0                          0           0  \n",
       "1            1 -0.288732            0                          3           1  \n",
       "2            3  1.783563            0                          2           0  \n",
       "3            3 -0.495961            0                          5           1  \n",
       "4            3 -1.117650            1                          2           1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Copying originak dataframe\n",
    "training_df_scaled = training_df.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "num_cols = ['JoiningYear', 'Age']\n",
    "training_df_scaled[num_cols] = scaler.fit_transform(training_df[num_cols])\n",
    "\n",
    "training_df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b7e01a",
   "metadata": {},
   "source": [
    "## Question 2: Why we use StandardScaler here?\n",
    "Penggunaan StandardScaler dalam konteks ini adalah untuk penskalaan fitur, yang merupakan langkah prapemrosesan yang umum dalam pembelajaran mesin. Penskalaan fitur membantu memastikan bahwa semua fitur (dalam hal ini, 'Tahun Bergabung' dan 'Usia') berada pada skala yang sama atau memiliki rentang nilai yang sama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19e50ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training feature: (3722, 13)\n",
      "Shape of testing feature: (931, 13)\n",
      "Shape of training label: (3722,)\n",
      "Shape of training label: (931,)\n"
     ]
    }
   ],
   "source": [
    "# Select Features\n",
    "feature = training_df_scaled.drop('LeaveOrNot', axis=1)\n",
    "\n",
    "target = training_df_scaled['LeaveOrNot']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature , target,\n",
    "                                                  shuffle = True,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=1)\n",
    "\n",
    "\n",
    "print('Shape of training feature:', X_train.shape)\n",
    "print('Shape of testing feature:', X_test.shape)\n",
    "print('Shape of training label:', y_train.shape)\n",
    "print('Shape of training label:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddb251c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_6 (Flatten)         (None, 13)                0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 300)               4200      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,401\n",
      "Trainable params: 34,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten (input_shape=[13]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02bad0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "117/117 [==============================] - 2s 8ms/step - loss: 0.6278 - accuracy: 0.6625 - val_loss: 0.6333 - val_accuracy: 0.6294\n",
      "Epoch 2/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5948 - accuracy: 0.6639 - val_loss: 0.6075 - val_accuracy: 0.6434\n",
      "Epoch 3/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5795 - accuracy: 0.6854 - val_loss: 0.5957 - val_accuracy: 0.6939\n",
      "Epoch 4/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5700 - accuracy: 0.7088 - val_loss: 0.5958 - val_accuracy: 0.6853\n",
      "Epoch 5/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5630 - accuracy: 0.7187 - val_loss: 0.5882 - val_accuracy: 0.6971\n",
      "Epoch 6/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5572 - accuracy: 0.7273 - val_loss: 0.5824 - val_accuracy: 0.7100\n",
      "Epoch 7/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5525 - accuracy: 0.7308 - val_loss: 0.5790 - val_accuracy: 0.7175\n",
      "Epoch 8/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5475 - accuracy: 0.7391 - val_loss: 0.5724 - val_accuracy: 0.7250\n",
      "Epoch 9/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5427 - accuracy: 0.7453 - val_loss: 0.5669 - val_accuracy: 0.7250\n",
      "Epoch 10/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5384 - accuracy: 0.7512 - val_loss: 0.5638 - val_accuracy: 0.7304\n",
      "Epoch 11/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5349 - accuracy: 0.7523 - val_loss: 0.5625 - val_accuracy: 0.7261\n",
      "Epoch 12/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5311 - accuracy: 0.7523 - val_loss: 0.5567 - val_accuracy: 0.7347\n",
      "Epoch 13/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5272 - accuracy: 0.7579 - val_loss: 0.5635 - val_accuracy: 0.7250\n",
      "Epoch 14/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5229 - accuracy: 0.7603 - val_loss: 0.5521 - val_accuracy: 0.7315\n",
      "Epoch 15/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5198 - accuracy: 0.7628 - val_loss: 0.5472 - val_accuracy: 0.7358\n",
      "Epoch 16/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5162 - accuracy: 0.7663 - val_loss: 0.5531 - val_accuracy: 0.7336\n",
      "Epoch 17/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5123 - accuracy: 0.7628 - val_loss: 0.5467 - val_accuracy: 0.7347\n",
      "Epoch 18/30\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7692 - val_loss: 0.5403 - val_accuracy: 0.7358\n",
      "Epoch 19/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5050 - accuracy: 0.7706 - val_loss: 0.5340 - val_accuracy: 0.7497\n",
      "Epoch 20/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5009 - accuracy: 0.7762 - val_loss: 0.5434 - val_accuracy: 0.7401\n",
      "Epoch 21/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4983 - accuracy: 0.7743 - val_loss: 0.5322 - val_accuracy: 0.7433\n",
      "Epoch 22/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4936 - accuracy: 0.7767 - val_loss: 0.5254 - val_accuracy: 0.7691\n",
      "Epoch 23/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4907 - accuracy: 0.7783 - val_loss: 0.5273 - val_accuracy: 0.7573\n",
      "Epoch 24/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4873 - accuracy: 0.7859 - val_loss: 0.5232 - val_accuracy: 0.7605\n",
      "Epoch 25/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4835 - accuracy: 0.7894 - val_loss: 0.5232 - val_accuracy: 0.7605\n",
      "Epoch 26/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4795 - accuracy: 0.7910 - val_loss: 0.5110 - val_accuracy: 0.7701\n",
      "Epoch 27/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4771 - accuracy: 0.7961 - val_loss: 0.5111 - val_accuracy: 0.7734\n",
      "Epoch 28/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4744 - accuracy: 0.8012 - val_loss: 0.5134 - val_accuracy: 0.7648\n",
      "Epoch 29/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.7947 - val_loss: 0.5029 - val_accuracy: 0.7766\n",
      "Epoch 30/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4670 - accuracy: 0.8004 - val_loss: 0.5026 - val_accuracy: 0.7755\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30 , validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "316c498c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 3ms/step\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "y_predict = np.argmax(prediction, axis=1)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c13d8064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.6294307196562836\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(\"Accuracy is:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcfa6c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2aa00e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23a52bc3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "117/117 [==============================] - 3s 9ms/step - loss: 0.6279 - accuracy: 0.6515 - val_loss: 0.6396 - val_accuracy: 0.6294\n",
      "Epoch 2/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5946 - accuracy: 0.6650 - val_loss: 0.6117 - val_accuracy: 0.6348\n",
      "Epoch 3/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5785 - accuracy: 0.6843 - val_loss: 0.5961 - val_accuracy: 0.6842\n",
      "Epoch 4/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5691 - accuracy: 0.7063 - val_loss: 0.5887 - val_accuracy: 0.7003\n",
      "Epoch 5/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5616 - accuracy: 0.7203 - val_loss: 0.5827 - val_accuracy: 0.7132\n",
      "Epoch 6/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5556 - accuracy: 0.7324 - val_loss: 0.5818 - val_accuracy: 0.7154\n",
      "Epoch 7/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5512 - accuracy: 0.7405 - val_loss: 0.5809 - val_accuracy: 0.7175\n",
      "Epoch 8/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5463 - accuracy: 0.7437 - val_loss: 0.5710 - val_accuracy: 0.7293\n",
      "Epoch 9/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5428 - accuracy: 0.7474 - val_loss: 0.5680 - val_accuracy: 0.7197\n",
      "Epoch 10/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5390 - accuracy: 0.7547 - val_loss: 0.5743 - val_accuracy: 0.7261\n",
      "Epoch 11/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5360 - accuracy: 0.7547 - val_loss: 0.5674 - val_accuracy: 0.7315\n",
      "Epoch 12/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5322 - accuracy: 0.7536 - val_loss: 0.5600 - val_accuracy: 0.7250\n",
      "Epoch 13/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5289 - accuracy: 0.7582 - val_loss: 0.5586 - val_accuracy: 0.7347\n",
      "Epoch 14/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5251 - accuracy: 0.7577 - val_loss: 0.5580 - val_accuracy: 0.7207\n",
      "Epoch 15/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5231 - accuracy: 0.7611 - val_loss: 0.5516 - val_accuracy: 0.7229\n",
      "Epoch 16/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5185 - accuracy: 0.7633 - val_loss: 0.5500 - val_accuracy: 0.7325\n",
      "Epoch 17/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5155 - accuracy: 0.7644 - val_loss: 0.5464 - val_accuracy: 0.7336\n",
      "Epoch 18/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5123 - accuracy: 0.7663 - val_loss: 0.5446 - val_accuracy: 0.7325\n",
      "Epoch 19/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5093 - accuracy: 0.7697 - val_loss: 0.5405 - val_accuracy: 0.7465\n",
      "Epoch 20/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5055 - accuracy: 0.7724 - val_loss: 0.5392 - val_accuracy: 0.7411\n",
      "Epoch 21/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5021 - accuracy: 0.7740 - val_loss: 0.5351 - val_accuracy: 0.7390\n",
      "Epoch 22/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.4993 - accuracy: 0.7751 - val_loss: 0.5321 - val_accuracy: 0.7519\n",
      "Epoch 23/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.4959 - accuracy: 0.7757 - val_loss: 0.5284 - val_accuracy: 0.7540\n",
      "Epoch 24/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.4927 - accuracy: 0.7802 - val_loss: 0.5259 - val_accuracy: 0.7669\n",
      "Epoch 25/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.4901 - accuracy: 0.7813 - val_loss: 0.5237 - val_accuracy: 0.7669\n",
      "Epoch 26/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.4860 - accuracy: 0.7848 - val_loss: 0.5258 - val_accuracy: 0.7605\n",
      "Epoch 27/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.4833 - accuracy: 0.7883 - val_loss: 0.5215 - val_accuracy: 0.7637\n",
      "Epoch 28/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.4798 - accuracy: 0.7869 - val_loss: 0.5142 - val_accuracy: 0.7691\n",
      "Epoch 29/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.4761 - accuracy: 0.7945 - val_loss: 0.5122 - val_accuracy: 0.7637\n",
      "Epoch 30/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.4737 - accuracy: 0.7894 - val_loss: 0.5116 - val_accuracy: 0.7744\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "Epoch 1/30\n",
      "117/117 [==============================] - 2s 9ms/step - loss: 0.6211 - accuracy: 0.6625 - val_loss: 0.6242 - val_accuracy: 0.6284\n",
      "Epoch 2/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5963 - accuracy: 0.6660 - val_loss: 0.6089 - val_accuracy: 0.6380\n",
      "Epoch 3/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5826 - accuracy: 0.6795 - val_loss: 0.6000 - val_accuracy: 0.6638\n",
      "Epoch 4/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5729 - accuracy: 0.6991 - val_loss: 0.5945 - val_accuracy: 0.6799\n",
      "Epoch 5/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5652 - accuracy: 0.7109 - val_loss: 0.5921 - val_accuracy: 0.6874\n",
      "Epoch 6/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5596 - accuracy: 0.7249 - val_loss: 0.5807 - val_accuracy: 0.7186\n",
      "Epoch 7/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5547 - accuracy: 0.7305 - val_loss: 0.5789 - val_accuracy: 0.7197\n",
      "Epoch 8/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5507 - accuracy: 0.7426 - val_loss: 0.5753 - val_accuracy: 0.7218\n",
      "Epoch 9/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5457 - accuracy: 0.7445 - val_loss: 0.5735 - val_accuracy: 0.7282\n",
      "Epoch 10/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5423 - accuracy: 0.7496 - val_loss: 0.5692 - val_accuracy: 0.7315\n",
      "Epoch 11/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5383 - accuracy: 0.7523 - val_loss: 0.5634 - val_accuracy: 0.7368\n",
      "Epoch 12/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5345 - accuracy: 0.7526 - val_loss: 0.5663 - val_accuracy: 0.7315\n",
      "Epoch 13/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5309 - accuracy: 0.7534 - val_loss: 0.5578 - val_accuracy: 0.7401\n",
      "Epoch 14/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5266 - accuracy: 0.7582 - val_loss: 0.5558 - val_accuracy: 0.7368\n",
      "Epoch 15/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5234 - accuracy: 0.7587 - val_loss: 0.5509 - val_accuracy: 0.7411\n",
      "Epoch 16/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5199 - accuracy: 0.7614 - val_loss: 0.5485 - val_accuracy: 0.7379\n",
      "Epoch 17/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5157 - accuracy: 0.7638 - val_loss: 0.5495 - val_accuracy: 0.7358\n",
      "Epoch 18/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5122 - accuracy: 0.7628 - val_loss: 0.5426 - val_accuracy: 0.7347\n",
      "Epoch 19/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5085 - accuracy: 0.7671 - val_loss: 0.5448 - val_accuracy: 0.7379\n",
      "Epoch 20/30\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 0.5046 - accuracy: 0.7679 - val_loss: 0.5348 - val_accuracy: 0.7368\n",
      "Epoch 21/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5009 - accuracy: 0.7679 - val_loss: 0.5308 - val_accuracy: 0.7487\n",
      "Epoch 22/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4979 - accuracy: 0.7714 - val_loss: 0.5321 - val_accuracy: 0.7465\n",
      "Epoch 23/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4934 - accuracy: 0.7759 - val_loss: 0.5350 - val_accuracy: 0.7508\n",
      "Epoch 24/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4896 - accuracy: 0.7775 - val_loss: 0.5207 - val_accuracy: 0.7573\n",
      "Epoch 25/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4861 - accuracy: 0.7821 - val_loss: 0.5333 - val_accuracy: 0.7444\n",
      "Epoch 26/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4816 - accuracy: 0.7886 - val_loss: 0.5170 - val_accuracy: 0.7680\n",
      "Epoch 27/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4792 - accuracy: 0.7886 - val_loss: 0.5139 - val_accuracy: 0.7787\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4753 - accuracy: 0.7947 - val_loss: 0.5087 - val_accuracy: 0.7744\n",
      "Epoch 29/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4716 - accuracy: 0.7934 - val_loss: 0.5045 - val_accuracy: 0.7712\n",
      "Epoch 30/30\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 0.4689 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7809\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Epoch 1/30\n",
      "117/117 [==============================] - 2s 8ms/step - loss: 0.6090 - accuracy: 0.6612 - val_loss: 0.6126 - val_accuracy: 0.6412\n",
      "Epoch 2/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5844 - accuracy: 0.6760 - val_loss: 0.6008 - val_accuracy: 0.6606\n",
      "Epoch 3/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5717 - accuracy: 0.7045 - val_loss: 0.5906 - val_accuracy: 0.6864\n",
      "Epoch 4/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5633 - accuracy: 0.7192 - val_loss: 0.5814 - val_accuracy: 0.7175\n",
      "Epoch 5/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5573 - accuracy: 0.7251 - val_loss: 0.5768 - val_accuracy: 0.7218\n",
      "Epoch 6/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5518 - accuracy: 0.7332 - val_loss: 0.5793 - val_accuracy: 0.7121\n",
      "Epoch 7/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5478 - accuracy: 0.7391 - val_loss: 0.5698 - val_accuracy: 0.7282\n",
      "Epoch 8/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5447 - accuracy: 0.7442 - val_loss: 0.5673 - val_accuracy: 0.7304\n",
      "Epoch 9/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5405 - accuracy: 0.7493 - val_loss: 0.5676 - val_accuracy: 0.7272\n",
      "Epoch 10/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5372 - accuracy: 0.7512 - val_loss: 0.5619 - val_accuracy: 0.7282\n",
      "Epoch 11/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5335 - accuracy: 0.7509 - val_loss: 0.5623 - val_accuracy: 0.7293\n",
      "Epoch 12/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5302 - accuracy: 0.7547 - val_loss: 0.5565 - val_accuracy: 0.7358\n",
      "Epoch 13/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5264 - accuracy: 0.7609 - val_loss: 0.5547 - val_accuracy: 0.7282\n",
      "Epoch 14/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5233 - accuracy: 0.7550 - val_loss: 0.5512 - val_accuracy: 0.7358\n",
      "Epoch 15/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5205 - accuracy: 0.7598 - val_loss: 0.5491 - val_accuracy: 0.7401\n",
      "Epoch 16/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5153 - accuracy: 0.7587 - val_loss: 0.5463 - val_accuracy: 0.7379\n",
      "Epoch 17/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5126 - accuracy: 0.7620 - val_loss: 0.5467 - val_accuracy: 0.7379\n",
      "Epoch 18/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5084 - accuracy: 0.7633 - val_loss: 0.5407 - val_accuracy: 0.7390\n",
      "Epoch 19/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5052 - accuracy: 0.7684 - val_loss: 0.5449 - val_accuracy: 0.7390\n",
      "Epoch 20/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5015 - accuracy: 0.7671 - val_loss: 0.5312 - val_accuracy: 0.7508\n",
      "Epoch 21/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4987 - accuracy: 0.7695 - val_loss: 0.5343 - val_accuracy: 0.7390\n",
      "Epoch 22/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4941 - accuracy: 0.7757 - val_loss: 0.5387 - val_accuracy: 0.7454\n",
      "Epoch 23/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4913 - accuracy: 0.7792 - val_loss: 0.5276 - val_accuracy: 0.7540\n",
      "Epoch 24/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.4868 - accuracy: 0.7797 - val_loss: 0.5234 - val_accuracy: 0.7605\n",
      "Epoch 25/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.4834 - accuracy: 0.7834 - val_loss: 0.5164 - val_accuracy: 0.7637\n",
      "Epoch 26/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4804 - accuracy: 0.7837 - val_loss: 0.5157 - val_accuracy: 0.7734\n",
      "Epoch 27/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4760 - accuracy: 0.7867 - val_loss: 0.5118 - val_accuracy: 0.7680\n",
      "Epoch 28/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4737 - accuracy: 0.7877 - val_loss: 0.5093 - val_accuracy: 0.7734\n",
      "Epoch 29/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4695 - accuracy: 0.7920 - val_loss: 0.5031 - val_accuracy: 0.7680\n",
      "Epoch 30/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4670 - accuracy: 0.7950 - val_loss: 0.5007 - val_accuracy: 0.7734\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "117/117 [==============================] - 2s 7ms/step - loss: 0.6274 - accuracy: 0.6480 - val_loss: 0.6294 - val_accuracy: 0.6327\n",
      "Epoch 2/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5992 - accuracy: 0.6655 - val_loss: 0.6114 - val_accuracy: 0.6305\n",
      "Epoch 3/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5837 - accuracy: 0.6709 - val_loss: 0.5998 - val_accuracy: 0.6455\n",
      "Epoch 4/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5725 - accuracy: 0.6913 - val_loss: 0.5949 - val_accuracy: 0.6595\n",
      "Epoch 5/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5651 - accuracy: 0.7045 - val_loss: 0.5843 - val_accuracy: 0.7111\n",
      "Epoch 6/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5581 - accuracy: 0.7211 - val_loss: 0.5781 - val_accuracy: 0.7315\n",
      "Epoch 7/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5521 - accuracy: 0.7297 - val_loss: 0.5759 - val_accuracy: 0.7197\n",
      "Epoch 8/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5485 - accuracy: 0.7426 - val_loss: 0.5728 - val_accuracy: 0.7293\n",
      "Epoch 9/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5431 - accuracy: 0.7461 - val_loss: 0.5710 - val_accuracy: 0.7304\n",
      "Epoch 10/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5391 - accuracy: 0.7485 - val_loss: 0.5630 - val_accuracy: 0.7368\n",
      "Epoch 11/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5346 - accuracy: 0.7547 - val_loss: 0.5681 - val_accuracy: 0.7272\n",
      "Epoch 12/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5302 - accuracy: 0.7569 - val_loss: 0.5570 - val_accuracy: 0.7422\n",
      "Epoch 13/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5272 - accuracy: 0.7577 - val_loss: 0.5537 - val_accuracy: 0.7433\n",
      "Epoch 14/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5234 - accuracy: 0.7577 - val_loss: 0.5542 - val_accuracy: 0.7325\n",
      "Epoch 15/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5185 - accuracy: 0.7641 - val_loss: 0.5486 - val_accuracy: 0.7422\n",
      "Epoch 16/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5150 - accuracy: 0.7636 - val_loss: 0.5433 - val_accuracy: 0.7551\n",
      "Epoch 17/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5106 - accuracy: 0.7676 - val_loss: 0.5447 - val_accuracy: 0.7433\n",
      "Epoch 18/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5073 - accuracy: 0.7697 - val_loss: 0.5467 - val_accuracy: 0.7422\n",
      "Epoch 19/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5033 - accuracy: 0.7665 - val_loss: 0.5332 - val_accuracy: 0.7551\n",
      "Epoch 20/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5003 - accuracy: 0.7727 - val_loss: 0.5320 - val_accuracy: 0.7444\n",
      "Epoch 21/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4955 - accuracy: 0.7770 - val_loss: 0.5407 - val_accuracy: 0.7487\n",
      "Epoch 22/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4918 - accuracy: 0.7754 - val_loss: 0.5221 - val_accuracy: 0.7648\n",
      "Epoch 23/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4884 - accuracy: 0.7800 - val_loss: 0.5198 - val_accuracy: 0.7637\n",
      "Epoch 24/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4841 - accuracy: 0.7832 - val_loss: 0.5164 - val_accuracy: 0.7637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4817 - accuracy: 0.7869 - val_loss: 0.5213 - val_accuracy: 0.7658\n",
      "Epoch 26/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4789 - accuracy: 0.7912 - val_loss: 0.5122 - val_accuracy: 0.7777\n",
      "Epoch 27/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.4742 - accuracy: 0.7958 - val_loss: 0.5045 - val_accuracy: 0.7755\n",
      "Epoch 28/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4708 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7723\n",
      "Epoch 29/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4673 - accuracy: 0.7963 - val_loss: 0.5001 - val_accuracy: 0.7809\n",
      "Epoch 30/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.8012 - val_loss: 0.4951 - val_accuracy: 0.7820\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Epoch 1/30\n",
      "117/117 [==============================] - 2s 7ms/step - loss: 0.6171 - accuracy: 0.6604 - val_loss: 0.6163 - val_accuracy: 0.6337\n",
      "Epoch 2/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5866 - accuracy: 0.6674 - val_loss: 0.6075 - val_accuracy: 0.6348\n",
      "Epoch 3/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5722 - accuracy: 0.6905 - val_loss: 0.5908 - val_accuracy: 0.6778\n",
      "Epoch 4/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5623 - accuracy: 0.7136 - val_loss: 0.5797 - val_accuracy: 0.7078\n",
      "Epoch 5/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5557 - accuracy: 0.7276 - val_loss: 0.5760 - val_accuracy: 0.7143\n",
      "Epoch 6/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5496 - accuracy: 0.7378 - val_loss: 0.5734 - val_accuracy: 0.7186\n",
      "Epoch 7/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5450 - accuracy: 0.7413 - val_loss: 0.5657 - val_accuracy: 0.7261\n",
      "Epoch 8/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5397 - accuracy: 0.7450 - val_loss: 0.5681 - val_accuracy: 0.7218\n",
      "Epoch 9/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5357 - accuracy: 0.7504 - val_loss: 0.5636 - val_accuracy: 0.7272\n",
      "Epoch 10/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5317 - accuracy: 0.7531 - val_loss: 0.5572 - val_accuracy: 0.7325\n",
      "Epoch 11/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5271 - accuracy: 0.7587 - val_loss: 0.5537 - val_accuracy: 0.7304\n",
      "Epoch 12/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5238 - accuracy: 0.7571 - val_loss: 0.5488 - val_accuracy: 0.7336\n",
      "Epoch 13/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5196 - accuracy: 0.7571 - val_loss: 0.5518 - val_accuracy: 0.7293\n",
      "Epoch 14/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5160 - accuracy: 0.7595 - val_loss: 0.5423 - val_accuracy: 0.7411\n",
      "Epoch 15/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5124 - accuracy: 0.7644 - val_loss: 0.5384 - val_accuracy: 0.7433\n",
      "Epoch 16/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.5088 - accuracy: 0.7665 - val_loss: 0.5431 - val_accuracy: 0.7347\n",
      "Epoch 17/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5048 - accuracy: 0.7654 - val_loss: 0.5403 - val_accuracy: 0.7368\n",
      "Epoch 18/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.5012 - accuracy: 0.7676 - val_loss: 0.5365 - val_accuracy: 0.7379\n",
      "Epoch 19/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4977 - accuracy: 0.7695 - val_loss: 0.5338 - val_accuracy: 0.7444\n",
      "Epoch 20/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4936 - accuracy: 0.7749 - val_loss: 0.5264 - val_accuracy: 0.7368\n",
      "Epoch 21/30\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 0.4908 - accuracy: 0.7749 - val_loss: 0.5192 - val_accuracy: 0.7551\n",
      "Epoch 22/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4867 - accuracy: 0.7778 - val_loss: 0.5232 - val_accuracy: 0.7519\n",
      "Epoch 23/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4837 - accuracy: 0.7837 - val_loss: 0.5137 - val_accuracy: 0.7573\n",
      "Epoch 24/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4799 - accuracy: 0.7834 - val_loss: 0.5103 - val_accuracy: 0.7637\n",
      "Epoch 25/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4770 - accuracy: 0.7867 - val_loss: 0.5079 - val_accuracy: 0.7669\n",
      "Epoch 26/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4737 - accuracy: 0.7896 - val_loss: 0.5056 - val_accuracy: 0.7734\n",
      "Epoch 27/30\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 0.4705 - accuracy: 0.7939 - val_loss: 0.5023 - val_accuracy: 0.7787\n",
      "Epoch 28/30\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7918 - val_loss: 0.5065 - val_accuracy: 0.7691\n",
      "Epoch 29/30\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7961 - val_loss: 0.4980 - val_accuracy: 0.7798\n",
      "Epoch 30/30\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 0.4613 - accuracy: 0.8036 - val_loss: 0.4964 - val_accuracy: 0.7884\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Average Accuracy: 0.6628108537201414\n"
     ]
    }
   ],
   "source": [
    "fold_accuracies = []\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_fold_train, X_fold_test = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_fold_train, y_fold_test = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten (input_shape=[13]),\n",
    "        keras.layers.Dense(300, activation=\"relu\"),\n",
    "        keras.layers.Dense(100, activation=\"relu\"),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=30, validation_data= (X_test, y_test))\n",
    "    \n",
    "    predictions = model.predict(X_fold_test)\n",
    "    fold_predictions = np.argmax(predictions, axis=1)\n",
    "    fold_accuracy = accuracy_score (y_fold_test, fold_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "\n",
    "average_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "print(\"Average Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "052cfaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "Mean Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "y_encoded = to_categorical(y)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_accuracies = []\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "\n",
    "    model = create_model()\n",
    "    model.fit(X_train, y_train, epochs=80, batch_size=10, verbose=0)\n",
    "\n",
    "    predict_x = model.predict(X_test)\n",
    "    classes_x = np.argmax(predict_x, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(np.argmax(y_test, axis=1), classes_x)\n",
    "    fold_accuracies.append(accuracy)\n",
    "\n",
    "mean_accuracy = np.mean(fold_accuracies)\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
